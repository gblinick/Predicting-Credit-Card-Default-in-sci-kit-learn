{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-depth Analysis (Applying Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1) Read the Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we progress further, we display the information about the dataset that we obtained from the dataset manual, that is, from Kaggle and the UCI Machine Learning Repository.\n",
    "\n",
    "From Kaggle, an overview of the variables:\n",
    "\n",
    "There are 25 variables:\n",
    "\n",
    "* ID: ID of each client\n",
    "* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
    "* SEX: Gender (1=male, 2=female)\n",
    "* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "* AGE: Age in years\n",
    "* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
    "* PAY_2: Repayment status in August, 2005 (scale same as above)\n",
    "* PAY_3: Repayment status in July, 2005 (scale same as above)\n",
    "* PAY_4: Repayment status in June, 2005 (scale same as above)\n",
    "* PAY_5: Repayment status in May, 2005 (scale same as above)\n",
    "* PAY_6: Repayment status in April, 2005 (scale same as above)\n",
    "* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
    "* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
    "* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
    "* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
    "* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
    "* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
    "* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
    "* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
    "* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
    "* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
    "* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
    "* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar) default.payment.next.month: Default payment (1=yes, 0=no)\n",
    "\n",
    "And from UCI:\n",
    "\n",
    "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables: \n",
    "* X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit. \n",
    "* X2: Gender (1 = male; 2 = female). \n",
    "* X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "* X4: Marital status (1 = married; 2 = single; 3 = others). \n",
    "* X5: Age (year). \n",
    "* X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
    "* X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. \n",
    "* X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential issue: We'll want to group values 5 and 6 for Education into one value (looking at the Kaggle description) since they both stand for \"unknown\". And perhaps we'll want to include 4 in that grouping since it has the value of \"others\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2) Review the Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import random\n",
    "import sklearn\n",
    "\n",
    "# Setup Seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'UCI_Credit_Card.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename) #, index_col=0)\n",
    "data = data.drop(columns='ID') # don't need ID column, because just the index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>26411</th>\n",
       "      <th>10651</th>\n",
       "      <th>29808</th>\n",
       "      <th>10034</th>\n",
       "      <th>11187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <td>390000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>41.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <td>48378.0</td>\n",
       "      <td>2634.0</td>\n",
       "      <td>6035.0</td>\n",
       "      <td>239963.0</td>\n",
       "      <td>3603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <td>52279.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>11782.0</td>\n",
       "      <td>224278.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <td>51176.0</td>\n",
       "      <td>1318.0</td>\n",
       "      <td>7241.0</td>\n",
       "      <td>196747.0</td>\n",
       "      <td>5881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <td>52286.0</td>\n",
       "      <td>36032.0</td>\n",
       "      <td>7277.0</td>\n",
       "      <td>108242.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4972.0</td>\n",
       "      <td>72480.0</td>\n",
       "      <td>3331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11270.0</td>\n",
       "      <td>2609.0</td>\n",
       "      <td>36440.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <td>4705.0</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>8710.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1318.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>8119.0</td>\n",
       "      <td>5881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <td>2712.0</td>\n",
       "      <td>36032.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11270.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28051.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>131904.0</td>\n",
       "      <td>8447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default.payment.next.month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               26411     10651     29808     10034     11187\n",
       "LIMIT_BAL                   390000.0  500000.0  250000.0  270000.0  200000.0\n",
       "SEX                              2.0       1.0       1.0       1.0       2.0\n",
       "EDUCATION                        1.0       1.0       1.0       3.0       2.0\n",
       "MARRIAGE                         1.0       2.0       1.0       1.0       1.0\n",
       "AGE                             41.0      54.0      34.0      53.0      39.0\n",
       "PAY_0                            0.0      -2.0       0.0       0.0      -1.0\n",
       "PAY_2                            0.0      -2.0       0.0       0.0       2.0\n",
       "PAY_3                            2.0      -2.0       0.0       0.0      -1.0\n",
       "PAY_4                            0.0      -2.0       0.0       0.0      -1.0\n",
       "PAY_5                            0.0      -2.0       0.0       0.0      -1.0\n",
       "PAY_6                           -2.0      -2.0       0.0       0.0      -1.0\n",
       "BILL_AMT1                    48378.0    2634.0    6035.0  239963.0    3603.0\n",
       "BILL_AMT2                    52279.0    1108.0   11782.0  224278.0     272.0\n",
       "BILL_AMT3                    51176.0    1318.0    7241.0  196747.0    5881.0\n",
       "BILL_AMT4                    52286.0   36032.0    7277.0  108242.0       0.0\n",
       "BILL_AMT5                        0.0       0.0    4972.0   72480.0    3331.0\n",
       "BILL_AMT6                        0.0   11270.0    2609.0   36440.0       0.0\n",
       "PAY_AMT1                      4705.0    1119.0    1131.0    8710.0       0.0\n",
       "PAY_AMT2                         0.0    1318.0    4000.0    8119.0    5881.0\n",
       "PAY_AMT3                      2712.0   36032.0    3000.0    4500.0      20.0\n",
       "PAY_AMT4                         0.0       0.0      99.0    3000.0    3331.0\n",
       "PAY_AMT5                         0.0   11270.0    1000.0    2000.0       0.0\n",
       "PAY_AMT6                         0.0   28051.0    6000.0  131904.0    8447.0\n",
       "default.payment.next.month       0.0       0.0       1.0       1.0       0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "data.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 24 columns):\n",
      "LIMIT_BAL                     30000 non-null float64\n",
      "SEX                           30000 non-null int64\n",
      "EDUCATION                     30000 non-null int64\n",
      "MARRIAGE                      30000 non-null int64\n",
      "AGE                           30000 non-null int64\n",
      "PAY_0                         30000 non-null int64\n",
      "PAY_2                         30000 non-null int64\n",
      "PAY_3                         30000 non-null int64\n",
      "PAY_4                         30000 non-null int64\n",
      "PAY_5                         30000 non-null int64\n",
      "PAY_6                         30000 non-null int64\n",
      "BILL_AMT1                     30000 non-null float64\n",
      "BILL_AMT2                     30000 non-null float64\n",
      "BILL_AMT3                     30000 non-null float64\n",
      "BILL_AMT4                     30000 non-null float64\n",
      "BILL_AMT5                     30000 non-null float64\n",
      "BILL_AMT6                     30000 non-null float64\n",
      "PAY_AMT1                      30000 non-null float64\n",
      "PAY_AMT2                      30000 non-null float64\n",
      "PAY_AMT3                      30000 non-null float64\n",
      "PAY_AMT4                      30000 non-null float64\n",
      "PAY_AMT5                      30000 non-null float64\n",
      "PAY_AMT6                      30000 non-null float64\n",
      "default.payment.next.month    30000 non-null int64\n",
      "dtypes: float64(13), int64(11)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns in this dataset have a numeric type. They are either float-valued (continuous) or int-valued (discrete). Nothing seems to be off, so we may continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3) Fixing the Issues (Data Cleaning):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Get rid of Bad Column Names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename columns\n",
    "data.rename(columns={'PAY_0': 'PAY_1', 'default.payment.next.month': 'default'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Replace Negative Values with 0 in Pay_X columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with with values for the PAY_X columns, a sensible solution is to convert all non-positive values to 0. The dataset description says that a value of -1 means \"pay duly\" and positive values represent a payment delay by that number of months. Therefore, converting -1 and -2 values to 0, and having 0 represent \"pay duly\" is logical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,7):\n",
    "    data.loc[data[\"PAY_\" + str(i)] < 0, \"PAY_\" + str(i)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Get rid of Values of 0 for Marriage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logical move is to group the 0 values with the \"Other\" values, coded as 3, so that is what we'll do:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"MARRIAGE\"] == 0, 'MARRIAGE'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Other\" for marriage can possibly refer to divorced, widowed, seperated, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Get rid of 0 Values for Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently coded as:\n",
    "EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 0 is not even in the dataset desciption, and we have 2 values for unknown. So a logical move is to convert the 0, 5 and 6 values to 4, which is what we'll do. \"Other\" can  refer to education less than high school or perhaps vocational training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = (data[\"EDUCATION\"] == 0) | (data[\"EDUCATION\"] == 5) | (data[\"EDUCATION\"] == 6) \n",
    "data.loc[replace,'EDUCATION'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4) Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to deal with SEX, EDUCATION, and MARRIAGE appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace_map = {'SEX': {1:\"Male\", 2:\"Female\"}, 'EDUCATION': {1: \"Grad School\", 2: \"University\", 3:\"High School\", 4:\"Other\"}, 'MARRIAGE': {1:\"Married\", 2:\"Single\", 3:\"Other\"}}\n",
    "# data.replace(replace_map, inplace=True)\n",
    "\n",
    "# data['default'] = data['default'].astype('category') \n",
    "# #Convert default variable from int64 to categorical variable\n",
    "\n",
    "# data = pd.get_dummies(data, columns=['SEX', 'EDUCATION', 'MARRIAGE'], prefix=['SEX', 'EDUCATION', 'MARRIAGE'], drop_first=True)\n",
    "# switch this to sklearn OneHotEncoder later\n",
    "\n",
    "# # Not import because will just use X and y\n",
    "# col_at_end = ['default']\n",
    "# data = data[[column for column in data if column not in col_at_end] + [column for column in col_at_end if column in data]]\n",
    "# ## Put default column at the end of the dataframe\n",
    "\n",
    "# # Don't use Pandas categoricals\n",
    "# data['PAY_1'] = data.PAY_1.astype('category')\n",
    "# data['PAY_2'] = data.PAY_2.astype('category')\n",
    "# data['PAY_3'] = data.PAY_3.astype('category')\n",
    "# data['PAY_4'] = data.PAY_4.astype('category')\n",
    "# data['PAY_5'] = data.PAY_5.astype('category')\n",
    "# data['PAY_6'] = data.PAY_6.astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the PAY_X columns now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['PAY_6', 'PAY_5', 'BILL_AMT6', 'PAY_AMT6']]\n",
    "df.columns = ['Repayment status in April', 'Repayment status in May', 'Amount of bill statement in April', 'Amount of previous payment in April']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repayment status in April</th>\n",
       "      <th>Repayment status in May</th>\n",
       "      <th>Amount of bill statement in April</th>\n",
       "      <th>Amount of previous payment in April</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7319.0</td>\n",
       "      <td>13899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>150.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>107495.0</td>\n",
       "      <td>116880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39819.0</td>\n",
       "      <td>223833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>244.0</td>\n",
       "      <td>856.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Repayment status in April  Repayment status in May  \\\n",
       "68                            0                        2   \n",
       "436                           0                        2   \n",
       "1875                          0                        2   \n",
       "2262                          0                        2   \n",
       "2272                          0                        2   \n",
       "\n",
       "      Amount of bill statement in April  Amount of previous payment in April  \n",
       "68                               7319.0                              13899.0  \n",
       "436                               150.0                                200.0  \n",
       "1875                           107495.0                             116880.0  \n",
       "2262                            39819.0                             223833.0  \n",
       "2272                              244.0                                856.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['Amount of bill statement in April'] < df['Amount of previous payment in April']) & (df['Repayment status in April'] < df['Repayment status in May'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent instances where our repayment status is **worse** and we've paid more than our bill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps Involved in Classification in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocess Data\n",
    "2. Create Train and Test Sets\n",
    "3. Instantiate the model/estimator  \n",
    "(Steps 1 and 3 can be combined in a Pipeline object)\n",
    "4. Specify Hyperparameter Space\n",
    "5. Instantiate GridSearchCV or RandomizedSearchCV objects\n",
    "6. Fit CV object to the Training Set\n",
    "7. Predict on the Test Set\n",
    "8. Compute Scores for the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models*:\n",
    "1. Logistic Regression (LR)\n",
    "2. K-Nearest Neighbor (KNN)\n",
    "3. Support Vector Machine (SVM)\n",
    "4. Decision Trees (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, scale, StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
    "from scipy.stats import randint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step 1) Preprocess Data\n",
    "\n",
    "# We will train our classifier with the following features:\n",
    "# Numeric features to be scaled: LIMIT_BAL, AGE, PAY_X, BIL_AMTX, and PAY_AMTX\n",
    "# Categorical features: SEX, EDUCATION, MARRIAGE\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data\n",
    "numeric_features = ['LIMIT_BAL', 'AGE', 'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', \n",
    "                     'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', \n",
    "                     'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
    "                   ]\n",
    "\n",
    "\n",
    "\n",
    "data['PAY_1'] = data.PAY_1.astype('float64')\n",
    "data['PAY_2'] = data.PAY_2.astype('float64')\n",
    "data['PAY_3'] = data.PAY_3.astype('float64')\n",
    "data['PAY_4'] = data.PAY_4.astype('float64')\n",
    "data['PAY_5'] = data.PAY_5.astype('float64')\n",
    "data['PAY_6'] = data.PAY_6.astype('float64')\n",
    "data['AGE'] = data.AGE.astype('float64')\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(categories='auto'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_features = ['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "# label_transformer = Pipeline(steps=[\n",
    "#     ('label', LabelEncoder())\n",
    "# ])\n",
    "# Use StratifiedShuffleSplit to get it to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "        #,('lab', label_transformer, label_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step 2) Split Data into Training and Test Sets\n",
    "\n",
    "y = data['default']#.values\n",
    "X = data.drop(['default'], axis=1)#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *1st Model: Logistic Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step 3: Instantiate the Estimator\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                     ('classifier', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "#### Step 4: Specify the Hyperparameter Space\n",
    "\n",
    "param_grid_lr = {\n",
    "    \n",
    "    'classifier__C': np.logspace(-5, 8, 15),\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "#### Step 5: Instantiate the CV Object\n",
    "\n",
    "lr_cv = GridSearchCV(lr, param_grid_lr, cv=5, iid=False)\n",
    "\n",
    "#### Step 6: Fit on Training\n",
    "\n",
    "t0 = time.time()\n",
    "lr_cv.fit(X_train, y_train)\n",
    "print(\"It takes \", time.time() - t0, \" seconds for LR fitting\")\n",
    "\n",
    "#### Step 7: Predict on Test\n",
    "\n",
    "y_pred_lr = lr_cv.predict(X_test)\n",
    "\n",
    "#### Step 8: Scoring\n",
    "\n",
    "##### Accuracy\n",
    "\n",
    "print(\"Mean cross-validated score of the best estimator: %.3f\" % lr_cv.best_score_)\n",
    "# Latest accuracy is 0.82\n",
    "\n",
    "print(\"Accuracy with LR on testing set is: %.3f\" % lr_cv.score(X_test, y_test))\n",
    "# Latest accuracy is 0.82\n",
    "\n",
    "print(\"Accuracy with LR on training set is: %.3f\" % lr_cv.score(X_train, y_train))\n",
    "# Latest accuracy is 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr_cv2 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                     ('classifier', LogisticRegressionCV(solver='liblinear', cv=10, Cs=np.logspace(-5, 8, 15) ))])\n",
    "lr_cv2.fit(X_train, y_train)\n",
    "\n",
    "lr_cv2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv2.named_steps['classifier'].C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean cross-validated score of the best_estimator: %.3f \" % lr_cv.best_score_)\n",
    "print(\"Parameter setting that gave the best results on the hold out data: C = %.3f\" % lr_cv.best_params_.get('classifier__C'))\n",
    "print(\"Parameter setting that gave the best results on the hold out data: penalty =\", lr_cv.best_params_.get('classifier__penalty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = lr_cv.best_estimator_.named_steps['classifier'].coef_\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Number of Features:\", coefs.size)\n",
    "print(\" Number of Selected Features:\", np.count_nonzero(coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train.join(y_train)\n",
    "test_data = X_test.join(y_test)\n",
    "\n",
    "if ('prob_of_default' in train_data):\n",
    "    train_data = train_data.drop(columns=['prob_of_default'])\n",
    "if ('prob_of_default' in test_data):\n",
    "    test_data = test_data.drop(columns=['prob_of_default'])\n",
    "\n",
    "probs_train = lr_cv.predict_proba(X_train)[:,1] # probs = probability of default\n",
    "probs_test = lr_cv.predict_proba(X_test)[:,1] # probs = probability of default\n",
    "\n",
    "train_data['prob_of_default'] = probs_train\n",
    "test_data['prob_of_default'] = probs_test\n",
    "\n",
    "train_data['train/test'] = 'train'\n",
    "test_data['train/test'] = 'test'\n",
    "\n",
    "new_data = train_data.append(test_data).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ranked = new_data.loc[new_data['train/test'] == 'train'].sort_values(by='prob_of_default')\n",
    "test_ranked = new_data.loc[new_data['train/test'] == 'test'].sort_values(by='prob_of_default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These guys in the training set default with a low probability of default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ranked.loc[(train_ranked.prob_of_default < 0.5) & (train_ranked.default == 1)].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Individual 18967 defaults with an assigned default probability of about 1%. This seems to have happened because she had a very large bill statement in September, just before the bankruptcy point. One takeaway then is to look at all customers with large bills in September and see how many default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ranked.loc[(train_ranked.PAY_1 == 0 ) & (train_ranked.BILL_AMT1 > 0)].default.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not the case that customers with PAY_1 = 0 and BILL_AMT1 > 0 default more than the average. Actually, they default less than the average. What about if we also factor in PAY_AMT1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ranked.loc[(train_ranked.PAY_1 == 0 ) & (train_ranked.BILL_AMT1 > 0) & (train_ranked.PAY_AMT1 == 0)].default.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definately higher, but only about the mean now. Can't create rule based on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BILL_AMTX is related to PAY_AMTX-1, not PAY_AMTX\n",
    "for i in range(6,1,-1):\n",
    "    corr1 = new_data['BILL_AMT' + str(i)].corr(new_data['PAY_AMT' + str(i-1)])\n",
    "    corr2 = new_data['BILL_AMT' + str(i)].corr(new_data['PAY_AMT' + str(i)])\n",
    "    print(corr1 - corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ranked.corr()['prob_of_default'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ranked.sort_values(by='BILL_AMT1', ascending=False).loc[:,['BILL_AMT1', 'PAY_AMT1', 'default', 'prob_of_default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lr_cv.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds  = roc_curve(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Area under the Curve*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(lr_cv, X, y, cv=5, scoring='roc_auc')\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Model: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#3\n",
    "knn = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                     ('classifier', KNeighborsClassifier())])\n",
    "#4\n",
    "param_grid_knn = {\n",
    "    'classifier__n_neighbors': np.arange(1,20)\n",
    "}\n",
    "\n",
    "#5\n",
    "knn_cv = RandomizedSearchCV(knn, param_grid_knn, cv=3, iid=False)\n",
    "\n",
    "#6\n",
    "t0 = time.time()\n",
    "knn_cv.fit(X_train, y_train)\n",
    "print(\"It takes \", time.time() - t0, \" seconds for KNN fitting\")\n",
    "# takes 185 seconds with 5 folds, 1 to 20 neighbors,\n",
    "\n",
    "#7\n",
    "y_pred_knn = knn_cv.predict(X_test)\n",
    "\n",
    "#8\n",
    "print(\"Accuracy with KNN is: \", knn_cv.score(X_test, y_test))\n",
    "# latest accuracy is 0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean cross-validated score of the best_estimator: %.3f \" % knn_cv.best_score_)\n",
    "print(\"Parameter setting that gave the best results on the hold out data: n_neighbors =\", knn_cv.best_params_.get('classifier__n_neighbors'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = knn_cv.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds  = roc_curve(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Area under the Curve*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(knn_cv, X, y, cv=5, scoring='roc_auc')\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3nd Model: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#3\n",
    "svm = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                     ('classifier', SVC())])\n",
    "#4\n",
    "param_grid_svm = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__gamma': [1, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "#5\n",
    "svm_cv = RandomizedSearchCV(svm, param_grid_svm, cv=3, iid=False)\n",
    "\n",
    "#6\n",
    "t0 = time.time()\n",
    "svm_cv.fit(X_train, y_train)\n",
    "print(\"It takes \", time.time() - t0, \" seconds for SVM fitting\")\n",
    "# takes 272 seconds with 3 folds\n",
    "\n",
    "#7\n",
    "y_pred_svm = svm_cv.predict(X_test)\n",
    "\n",
    "#8\n",
    "print(\"Mean cross-validated score of the best estimator: %.3f\" % svm_cv.best_score_)\n",
    "print(\"Accuracy with LR on testing set is: %.3f\" % svm_cv.score(X_test, y_test))\n",
    "print(\"Accuracy with LR on training set is: %.3f\" % svm_cv.score(X_train, y_train))\n",
    "\n",
    "y_pred_prob = svm_cv.predict_proba(X_test)[:,1]\n",
    "print(\"ROC AUC score is: %.3f\" % roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4th Model: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#3\n",
    "dt = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                     ('classifier', DecisionTreeClassifier())])\n",
    "#4\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_grid_dt = {'classifier__max_depth': [3, None],\n",
    "                'classifier__max_features': randint(1, 9),\n",
    "                'classifier__min_samples_leaf': randint(1, 9),\n",
    "                'classifier__criterion': [\"gini\", \"entropy\"]}\n",
    "\n",
    "#5\n",
    "dt_cv = RandomizedSearchCV(dt, param_grid_dt, cv=10, iid=False)\n",
    "\n",
    "#6\n",
    "t0 = time.time()\n",
    "dt_cv.fit(X_train, y_train)\n",
    "print(\"It takes \", time.time() - t0, \" seconds for DT fitting\")\n",
    "# takes 11 seconds with 10 folds\n",
    "\n",
    "#7\n",
    "y_pred_dt = dt_cv.predict(X_test)\n",
    "\n",
    "#8\n",
    "print(\"Mean cross-validated score of the best estimator: %.3f\" % dt_cv.best_score_)\n",
    "print(\"Accuracy with LR on testing set is: %.3f\" % dt_cv.score(X_test, y_test))\n",
    "print(\"Accuracy with LR on training set is: %.3f\" % dt_cv.score(X_train, y_train))\n",
    "\n",
    "y_pred_prob = dt_cv.predict_proba(X_test)[:,1]\n",
    "print(\"ROC AUC score is: %.3f\" % roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5th Model: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run import_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i std_preprocessing_and_splitting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes  76.9420096874237  seconds for Random Forest fitting\n",
      "Mean cross-validated score of the best estimator: 0.813\n",
      "Accuracy with LR on testing set is: 0.820\n",
      "Accuracy with LR on training set is: 0.999\n",
      "ROC AUC score is: 0.781\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#3\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                     ('classifier', RandomForestClassifier())])\n",
    "#4\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_grid_rf = {'classifier__n_estimators': [1, 10, 50, 100]}\n",
    "\n",
    "#5\n",
    "rf_cv = GridSearchCV(rf, param_grid_rf, cv=10, iid=False)\n",
    "\n",
    "#6\n",
    "t0 = time.time()\n",
    "rf_cv.fit(X_train, y_train)\n",
    "print(\"It takes \", time.time() - t0, \" seconds for Random Forest fitting\")\n",
    "\n",
    "#7\n",
    "y_pred_rf = rf_cv.predict(X_test)\n",
    "\n",
    "#8\n",
    "print(\"Mean cross-validated score of the best estimator: %.3f\" % rf_cv.best_score_)\n",
    "print(\"Accuracy with Random Forest on testing set is: %.3f\" % rf_cv.score(X_test, y_test))\n",
    "print(\"Accuracy with Random Forest on training set is: %.3f\" % rf_cv.score(X_train, y_train))\n",
    "\n",
    "y_pred_prob = rf_cv.predict_proba(X_test)[:,1]\n",
    "print(\"ROC AUC score is: %.3f\" % roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
