{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have Data Call import Data\n",
    "%run import_data.py #import data into dataframe, drop ID column, and clean up PAY_0, PAY_X, MARRIAGE, and EDUCATION columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes  67.18677973747253  seconds for LR fitting\n",
      "Mean cross-validated score of the best estimator: 0.779\n",
      "Accuracy with LR on testing set is: 0.779\n",
      "Accuracy with LR on training set is: 0.779\n",
      "ROC AUC score is: 0.500\n"
     ]
    }
   ],
   "source": [
    "#### Step 1) Preprocess Data\n",
    "\n",
    "# We will train our classifier with the following features:\n",
    "# Numeric features to be scaled: LIMIT_BAL, AGE, PAY_X, BIL_AMTX, and PAY_AMTX\n",
    "# Categorical features: SEX, EDUCATION, MARRIAGE\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data\n",
    "numeric_features = ['LIMIT_BAL', 'AGE', \n",
    "                     'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', \n",
    "                     'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
    "                   ]\n",
    "\n",
    "\n",
    "\n",
    "data['PAY_1'] = data.PAY_1.astype('float64')\n",
    "data['PAY_2'] = data.PAY_2.astype('float64')\n",
    "data['PAY_3'] = data.PAY_3.astype('float64')\n",
    "data['PAY_4'] = data.PAY_4.astype('float64')\n",
    "data['PAY_5'] = data.PAY_5.astype('float64')\n",
    "data['PAY_6'] = data.PAY_6.astype('float64')\n",
    "data['AGE'] = data.AGE.astype('float64')\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(categories='auto'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "        #,('lab', label_transformer, label_features)\n",
    "    ])\n",
    "\n",
    "#### Step 2) Split Data into Training and Test Sets\n",
    "\n",
    "y = data['default']#.values\n",
    "X = data.drop(['default'], axis=1)#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
    "\n",
    "#### Step 3: Instantiate the Estimator\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                     ('classifier', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "#### Step 4: Specify the Hyperparameter Space\n",
    "\n",
    "param_grid_lr = {\n",
    "    \n",
    "    'classifier__C': np.logspace(-5, 8, 15),\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "#### Step 5: Instantiate the CV Object\n",
    "\n",
    "lr_cv = GridSearchCV(lr, param_grid_lr, cv=5, iid=False)\n",
    "\n",
    "#### Step 6: Fit on Training\n",
    "\n",
    "t0 = time.time()\n",
    "lr_cv.fit(X_train, y_train)\n",
    "print(\"It takes \", time.time() - t0, \" seconds for LR fitting\")\n",
    "\n",
    "#### Step 7: Predict on Test\n",
    "\n",
    "y_pred_lr = lr_cv.predict(X_test)\n",
    "\n",
    "#### Step 8: Scoring\n",
    "\n",
    "##### Accuracy\n",
    "\n",
    "print(\"Mean cross-validated score of the best estimator: %.3f\" % lr_cv.best_score_)\n",
    "print(\"Accuracy with LR on testing set is: %.3f\" % lr_cv.score(X_test, y_test))\n",
    "print(\"Accuracy with LR on training set is: %.3f\" % lr_cv.score(X_train, y_train))\n",
    "\n",
    "y_pred_prob = lr_cv.predict_proba(X_test)[:,1]\n",
    "print(\"ROC AUC score is: %.3f\" % roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
